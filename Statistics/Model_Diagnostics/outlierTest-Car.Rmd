---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




Outliers
===========================================

* *"Outliers are sample values that cause surprise in relation to the majority of the sample"* 

* (W.N. Venables and B.D. Ripley. 2002. Modern applied statistics with S. New York: Springer, p.119).


* Crucially, surprise is in the mind of the beholder and is dependent on some explicit model of the data. 

* Importantly, Normality is only an assumption:There may be another model under which the outlier is not surprising at all, say if the data really are lognormal or 
gamma rather than normal. 


---


```{r}

library(faraway)
data("cheddar")

```

---

Outliers
===========================================



* Data points that diverge in a big way from the overall pattern are referred to as ``outliers".

* In the case of Simple Linear Regression, there are four ways that a data point might be considered an outlier.


  *  It could have an extreme X value compared to other data points.
  *  It could have an extreme Y value compared to other data points.
  *  It could have extreme X and Y values.
  *  It might be distant from the rest of the data, even without extreme X or Y values.

---

Outliers
===========================================



*  After a regression line has been computed for a group of data, a point which lies far from the line 
(and thus has a large residual value) is known as an outlier. 
* Such points may represent erroneous data, or may indicate a poorly fitting regression line. 

*  If a point lies far from the other data in the horizontal direction, it is known as an ***influential observation***. 
* The reason for this distinction is that these points have may have a significant impact on the slope of the regression line.


#### ``outlierTest()``
* Suppose we have some fitted models and we would like to see if there are any outliers. 

* For this purpose, we can use ``outlierTest()`` from {car} R package. 






```{r}
library(car)
outlierTest(Fit_1)   
```

```{r}

outlierTest(Fit_2)   
```



```{r}

outlierTest(Fit_3)   
```

```{r}

outlierTest(Fit_4)   
```


### Outliers and Influential Observations

\begin{quote}
"Outliers are sample values that cause surprise in relation to the majority of the sample" (W.N. Venables and B.D. Ripley. 2002. Modern applied statistics with S. New York: Springer, p.119).
\end{quote}

Crucially, surprise is in the mind of the beholder and is dependent on some explicit model of the data. 

Importantly, Normality is only an assumption:There may be another model under which the outlier is not surprising at all, say if the data really are lognormal or 
gamma rather than normal. 

### Outliers

Data points that diverge in a big way from the overall pattern are referred to as ``outliers".\\ 
In the case of Simple Linear Regression, there are four ways that a data point might be considered an outlier.



* It could have an extreme X value compared to other data points.
* It could have an extreme Y value compared to other data points.
* It could have extreme X and Y values.
* It might be distant from the rest of the data, even without extreme X or Y values.


* After a regression line has been computed for a group of data, a point which lies far from the line 
(and thus has a large residual value) is known as an outlier. 
Such points may represent erroneous data, or may indicate a poorly fitting regression line. 

* If a point lies far from the other data in the horizontal direction, it is known as an \textit{\textbf{influential observation}}. 
The reason for this distinction is that these points have may have a significant impact on the slope of the regression line.

-------------------------------
### Identifying Outliers

Possible outliers can be identified by looking at the diagnostic plot of the residuals

Another approach is to use the <tt>outlierTest()</tt> function of the ***car*** package:

### outlierTest()
Suppose we have a two fitted models and we would like to see if there are any outliers. 

For this purpose, we can use outlierTest() from \texttt{library(car)} in R. 


```{r}
#If package not installed, uncomment next line.
#install.packages("car")

library(car)
outlierTest(Fit1)  
```


```{r}
outlierTest(Fit2)   
```

The row numbers ( here : 21, 15 and 177) indicate the outlier points in the data.






Suppose we have a two fitted models and we would like to see if there are any outliers. 

For this purpose, we can use \texttt{outlierTest()} from \texttt{library(car)} in R. 

%Currently facing a problem in interpreting the results.



```{r}
library(car)
outlierTest(fit1)   

**Result:**
    rstudent unadjusted p-value  Bonferonni p
21    -4.12            4.39e-05        0.0209
15     -4.08            5.39e-05        0.0257

outlierTest(fit2)   

**Result:**
No Studentized residuals with Bonferonni p < 0.05
Largest |rstudent|:
    rstudent unadjusted p-value      Bonferonni p
177    -2.52             0.0119                NA
```


The row numbers ( here : 21, 15 and 177) indicate the outlier points in the data.


