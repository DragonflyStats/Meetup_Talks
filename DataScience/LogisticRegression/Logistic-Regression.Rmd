---
title: "Logistic Regression"
author: "Data Science with R"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
output:
  rmdformats::readthedown:
    toc_depth: 3
    use_bookdown: TRUE
    #code_folding: hide
    fig_caption: TRUE


html_document:
  fig_caption: yes
  theme: flatly #sandstone #spacelab #
  highlight: pygments
  number_sections: TRUE
  toc: TRUE
  toc_width: 40
  toc_depth: 2
  toc_float:
    smooth_scroll: FALSE


---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
```
  
```{r import_libraries, echo=FALSE, message=FALSE}
# library(conflicted)
library(tidyverse)
# library(scales)
# library(cowplot)
# library(magrittr)

# library(rlang)
# library(stringr)
# library(glue)
# library(purrr)
# library(furrr)
# library(arules)
# library(arulesViz)
# library(DT)
# library(tidygraph)
# library(rfm)
#source("lib_utils.R")
# resolve_conflicts(
#   c("magrittr", "rlang", "dplyr", "readr", "purrr", "ggplot2", "arules",
#     "Matrix", "DT")
# )

knitr::opts_chunk$set(
  tidy       = FALSE,
  cache      = FALSE,
  warning    = FALSE,
  message    = FALSE,
  fig.height =     8,
  fig.width  =    12
)

options(
  width = 90L,
  warn  = 1
)

#theme_set(theme_cowplot())
set.seed(1234)
#plan(multisession)
```

Logistic Regression
===============================

## Binary Classification

Unlike the models we discussed previously, logistic regression is used for classification
tasks. Recall that the goal in classification tasks is to find a function that maps an
observation to its associated class or label. A learning algorithm must use pairs of
feature vectors and their corresponding labels to induce the values of the mapping
function's parameters that produce the best classifier, as measured by a particular
performance metric. In binary classification, the classifier must assign instances to one
of the two classes. 

#### Examples 
Examples of binary classification include predicting whether or not
a patient has a particular disease, whether or not an audio sample contains human
speech, or whether or not the Duke men's basketball team will lose in the first round
of the NCAA tournament. In multiclass classification, the classifier must assign one
of several labels to each instance. In multilabel classification, the classifier must assign
a subset of the labels to each instance. In this chapter, we will work through several
classification problems using logistic regression, discuss performance measures for the
classification task, and apply some of the feature extraction techniques you learned in
the previous chapter.

Formulaes
===================================

## Logits

Logits are defined as the ratio of the probability to its complement, or the ratio of
favorable to unfavorable cases. If the probability of an event is a half, the
odds are one-to-one or even.

$$ odds_i = \frac{\pi_i}{1-\pi_i}  $$

calculating the logit or log-odds


$$ Log(odds_i) = log left( \frac{\pi_i}{1-\pi_i} \right)  $$


```{r child = "segments/LR02_Assumptions.Rmd"}
```

```{r child = "segments/LR03_Logits_Oddsratio.Rmd"}
```

```{r child = "segments/LR13_Omnibus_Test.Rmd"}
```






Model Performace
=================================


## Model Accuracy

```{r echo=FALSE}
# http://www.unt.edu/rss/class/Jon/Benchmarks/CrossValidation1_JDS_May2011.pdf
```

* Prediction error refers to the discrepancy or difference between a predicted value (based on a
model) and the actual value. In the standard regression situation, prediction error refers to how
well our regression equation predicts the outcome variable scores of new cases based on
applying the model (coefficients) to the new casesâ€™ predictor variable scores.

## Binary Classification Metrics
Binary classification performance metrics
A variety of metrics exist to evaluate the performance of binary classifiers against
trusted labels. The most common metrics are accuracy, precision, recall, F1 measure,
and ROC AUC score. All of these measures depend on the concepts of true positives,
true negatives, false positives, and false negatives. Positive and negative refer to the
classes. 


----------------------------------------

True and false denote whether the predicted class is the same as the true class.
For our SMS spam classifier, a true positive prediction is when the classifier correctly
predicts that a message is spam. A true negative prediction is when the classifier
correctly predicts that a message is ham. A prediction that a ham message is spam
is a false positive prediction, and a spam message incorrectly classified as ham is a
false negative prediction. 

------------------------------

## Commonly Used Metrics

\begin{equation}
\text{Accuracy}=\frac{TP+TN}{TP+FP+FN+TN}
\end{equation}

\begin{equation}
\text{Precision}=\frac{TP}{TP+FP} \, 
\end{equation}

\begin{equation}
\text{Recall}=\frac{TP}{TP+FN} \, 
\end{equation}



Summary
===================================
### Summary

* Logistic regression, also called a logit model, is used to model ***dichotomous*** response variables. 
* In the logit model the ***log odds*** of the outcome is modeled as a linear combination of the predictor variables.
