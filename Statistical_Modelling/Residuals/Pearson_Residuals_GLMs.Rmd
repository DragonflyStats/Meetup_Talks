---
title: "Pearson Residuals"
subtitle: "General Linear Modesl"
author: DragonflyStats.github.io
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---


### Pearson Residuals






The Pearson residual is the raw residual divided by the square root of the variance function $V(\mu).$
The Pearson residual is the individual contribution to the Pearson $\chi^2$ statistic. 

For a binomial distribution with mi trials in the ith observation, it is defined as

\[ r_{Pi} = \sqrt{ m_{i}}
 \frac{r_{i}}{\sqrt{V(\hat{ \mu_{i}})}} \]
For other distributions, the Pearson residual is defined as

\[ r_{Pi} = \frac{r_{i}}{\sqrt{V(\hat{ \mu_{i}})}}\]
The Pearson residuals can be used to check the model fit at each observation for generalized linear models. 
%These residuals are stored in variables named RP_yname for each response variable, where yname is the response variable name. 
The standardized and studentized Pearson residuals are
\[
r_{Psi} = \frac{r_{Pi}}{\sqrt{\hat{ \phi} (1- h_{i})} } \]
\[ r_{Pti} = \frac{r_{Pi}}{\sqrt{ \hat{ \phi}_{(i)}
 (1- h_{i})} } \]




```{r, include=FALSE,echo=FALSE}


### Pearson and Deviance Residuals

# https://v8doc.sas.com/sashtml/insight/chap39/sect55.htm


# - http://stats.stackexchange.com/questions/24975/logistic-regression-getting-pearson-standardized-residuals-in-r-vs-stata
# - https://onlinecourses.science.psu.edu/stat504/book/export/html/160
```

* Pearson residuals are obtained by dividing the each observation's raw residual by the square root of the corresponding variance. 

* The idea is to get something that has variance 1, approximately. In your example, try this;


```{r}
set.seed(3141)
x1 <- rnorm(100)
x2 <- rnorm(100)
y <- rbinom(100, 1, 0.25)
```


```{r}
glm1 <- glm(y~x1+x2, family=binomial)
f1 <- fitted(glm1) # the fitted probability of y=1, for each observation
```

```{r}
plot( residuals(glm1, "pearson"), (y-f1)/sqrt(f1*(1-f1)))
abline(0,1)        # they match

```


The 'gap' occurs because the residuals where Y=1 are on one side, and those with Y=0 are on the other. 

Standardized residuals are a different animal; they divide by the estimated standard deviation of the residual; you can obtain them in R using <tt>rstandard()</tt>, though for non-linear GLMs it uses a linear approximation in the calculation.

NB residuals of any form tend not to be terribly helpful in logistic regression. With independent binary data, the only real concern is whether we've specified the mean correctly - and with modest sample sizes, plots of residuals typically provide little power to assess that.
