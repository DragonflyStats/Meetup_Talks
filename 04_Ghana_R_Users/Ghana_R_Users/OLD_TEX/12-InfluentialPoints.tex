
--------------------------------------------------- % 
\section{Leverage and Influence}

###Summary of Influence Statistics}
###rstudent}
The studentized residual RSTUDENT is estimated by $s(1. ^2$ without the ith observation, not by $s^2$. For example,

\[\mbox{RSTUDENT()</tt>= \frac{r_i}{s_{(1. ()</tt>\sqrt{(1 - h_1. }()</tt>\]
Observations with RSTUDENT larger than 2 in absolute value may need some attention.






*  \textbf{Studentized Residuals()</tt>– Residuals divided by their estimated standard errors (like t-statistics). Observations with values larger than 3 in absolute value are considered outliers.
*  \textbf{Leverage Values (Hat Diag)()</tt>– Measure of how far an observation is from the others in terms of the levels of the independent variables (not the dependent variable). Observations with values larger than $2(k+1)/n$ are considered to be potentially highly influential, where k is the number of predictors and n is the sample size.
*  \textbf{DFFITS()</tt>– Measure of how much an observation has effected its fitted value from the regression model. Values larger than $2\sqrt{(k+1)/n}$ in absolute value are considered highly influential. %Use standardized DFFITS in SPSS.
*  \textbf{DFBETAS()</tt>– Measure of how much an observation has effected the estimate of a regression coefficient (there is one DFBETA for each regression coefficient, including the intercept). Values larger than 2/sqrt(n) in absolute value are considered highly influential.
\\
The measure that measures how much impact each observation has on a particular predictor is DFBETAs The DFBETA for a predictor and for a particular observation is the difference between the regression coefficient calculated for all of the data and the regression coefficient calculated with the observation deleted, scaled by the standard error calculated with the observation deleted. 

*  \textbf{Cook’s D()</tt>– Measure of aggregate impact of each observation on the group of regression coefficients, as well as the group of fitted values. Values larger than 4/n are considered highly influential.



\section{Other Measures of Influence}
The impact of an observation on a regression fitting can be determined by the difference between the estimated regression coefficient of a model with all observations and the estimated coefficient when the particular observation is deleted. The measure DFBETA is the studentized value of this difference.

Influence arises at two stages of the LME model. Firstly when $V$ is estimated by $\hat{V}$, and subsequent
estimations of the fixed and random regression coefficients $\beta$ and $u$, given $\hat{V}$.



\subsubsection{DFBETA}
A group of measures that measures how much impact each observation has on a particular predictor are the DFBETAs. The DFBETA for a predictor and for a particular observation is the difference between the regression coefficient calculated for all of the data and the regression coefficient calculated with the observation deleted,  scaled by the standard error calculated with the observation deleted.

%\subsubsection{DFBETA()</tt>%1.16.3
\begin{eqnarray}
DFBETA_{a()</tt>&=& \hat{\beta()</tt>- \hat{\beta}_{(a)()</tt>\\
&=& B(Y-Y_{\bar{a}}
\end{eqnarray}

For $k$ predictors in the mode, there ar $k+1$ dfbetas.

% Interpret


\subsubsection{DFFITS()</tt>%1.16.1
DFFITS is a statistical measured designed to a show how influential an observation is in a statistical model. It is closely related to the studentized residual.
\begin{displaymath()</tt>DFFITS = {\widehat{y_i()</tt>-
\widehat{y_{i(k)}()</tt>\over s_{(k)()</tt>\sqrt{h_{ii}}()</tt>\end{displaymath}


\subsubsection{COVRATIO}
The COVRATIO statistic measures the change in 
the determinant of the covariance matrix of the estimates by deleting the ith observation:

\[ COVRATIO = \frac{det ( s^2_{(1. ()</tt>(X_{(1. }'X_{(1. })^{-1()</tt>) )}{ det ( s^2 (X'X)^{-1()</tt>) ()</tt> \]
%Belsley, Kuh, and Welsch suggest that observations with

Observations with

\[|{COVRATIO()</tt>- 1| \ge \frac{3k}{n}\]
where k is the number of parameters in the model and n is the number of observations used to fit the model, are worth further investigation.

%\subsubsection{PRESS()</tt>%1.16.2
%The prediction residual sum of squares (PRESS) is an value associated with this calculation. When fitting linear models, PRESS can be used as a criterion for model selection, with smaller values indicating better model fits.
%\begin{equation}
%PRESS = \sum(y-y^{(k)})^2
%\end{equation}
%
%
%
%*   $e_{-Q()</tt>= y_{Q()</tt>- x_{Q}\hat{\beta}^{-Q}$
%*   $PRESS_{(U)()</tt>= y_{i()</tt>- x\hat{\beta}_{(U)}$
%


%-------------------------------------------------------------- %
\newpage

###Influential Observations : DFBeta and DFBetas}
%% http://stats.stackexchange.com/questions/22161/how-to-read-cooks-distance-plots
%Cook's distance refers to how far, on average, predicted y-values will move if the observation in question is dropped from the data set. dfbeta refers to how much a parameter estimate changes if the observation in question is dropped from the data set. Note that with k covariates, there will be k+1 dfbetas (the intercept,$\beta_0$, and 1 $\beta$ for each covariate). Cook's distance is presumably more important to you if you are doing predictive modeling, whereas dfbeta is more important in explanatory modeling.




